import axios from 'axios';
import { isFirebaseConfigured } from '@/lib/firebase';
import { 
  analyzeWithO3ViaFunction, 
  analyzeImageWithO3ViaFunction,
  analyzePerplexityWithGPT4MiniViaFunction,
  transcribeAudioViaFunction,
  enrichReferencesWithWebSearchViaFunction,
  addCitationsToSectionsViaFunction
} from '@/lib/firebase-functions';
import { medGemmaClient } from './medgemma-client';
import { httpsCallable, getFunctions } from 'firebase/functions';
import { app } from '@/lib/firebase';

interface PerplexityResponse {
  citations: any[];
  answer: string;
  search_results?: Array<{
    title: string;
    url: string;
    date?: string;
  }>;
}

interface SectionContent {
  type: string;
  content: string;
}

const sectionTitles = {
  CLINICAL_CONTEXT: "1. Contexte clinique",
  KEY_DATA: "2. Donn√©es cl√©s",
  DIAGNOSTIC_HYPOTHESES: "3. Hypoth√®ses diagnostiques",
  COMPLEMENTARY_EXAMS: "4. Examens compl√©mentaires recommand√©s",
  THERAPEUTIC_DECISIONS: "5. D√©cisions th√©rapeutiques",
  PROGNOSIS_FOLLOWUP: "6. Pronostic & suivi",
  PATIENT_EXPLANATIONS: "7. Explications au patient"
};

export class AIClientService {
  private perplexityApiKey: string | undefined;
  private openaiApiKey: string | undefined;
  private isProduction: boolean = false;
  private useFirebaseFunctions: boolean = false;

  // Nouveau : stockage de la cha√Æne de requ√™tes/r√©ponses
  private requestChain: Array<{
    timestamp: string;
    model: string;
    type: string;
    request: string;
    response: string;
  }> = [];

  constructor() {
    // Cl√©s API expos√©es c√¥t√© client - √Ä utiliser uniquement pour des projets de d√©monstration
    this.perplexityApiKey = process.env.NEXT_PUBLIC_PERPLEXITY_API_KEY;
    this.openaiApiKey = process.env.NEXT_PUBLIC_OPENAI_API_KEY;
    
    // D√©tecter si on est en production
    if (typeof window !== 'undefined') {
      this.isProduction = window.location.hostname !== 'localhost' && window.location.hostname !== '127.0.0.1';
    }
    
    // Utiliser Firebase Functions si Firebase est configur√© et qu'on est en production
    this.useFirebaseFunctions = this.isProduction && isFirebaseConfigured();
    
    if (this.useFirebaseFunctions) {
      console.log('Mode production d√©tect√© - Utilisation de Firebase Functions pour OpenAI');
    }
  }

  // M√©thode pour r√©cup√©rer la cha√Æne de requ√™tes
  getRequestChain() {
    return [...this.requestChain];
  }

  // M√©thode pour r√©initialiser la cha√Æne
  clearRequestChain() {
    this.requestChain = [];
  }

  // Ajouter un √©l√©ment √† la cha√Æne de requ√™tes
  addToRequestChain(entry: {
    timestamp: string;
    model: string;
    requestType: string;
    request: string;
    response?: any;
  }) {
    this.requestChain.push({
      timestamp: entry.timestamp,
      model: entry.model,
      type: entry.requestType,
      request: entry.request,
      response: entry.response || ''
    });
  }

  hasApiKeys(): boolean {
    return !!this.perplexityApiKey && !!this.openaiApiKey;
  }

  getOpenAIApiKey(): string | undefined {
    return this.openaiApiKey;
  }

  async searchWithPerplexity(
    clinicalContext: string, 
    medgemmaAnalysis: string = '', 
    o3Analysis: string = ''
  ): Promise<PerplexityResponse> {
    if (!this.perplexityApiKey) {
      throw new Error('Cl√© API Perplexity non configur√©e');
    }

    // Construire le prompt structur√© pour Perplexity
    const query = `Recherche acad√©mique approfondie bas√©e sur ce cas clinique et les analyses fournies:

CAS CLINIQUE:
${clinicalContext}

${medgemmaAnalysis ? `ANALYSE D'IMAGERIE (MedGemma):
${medgemmaAnalysis}

` : ''}${o3Analysis ? `ANALYSE CLINIQUE PR√âLIMINAIRE (o3):
${o3Analysis}

` : ''}INSTRUCTIONS IMPORTANTES:
1. Fais une recherche acad√©mique exhaustive sur ce cas clinique
2. Concentre-toi sur les publications m√©dicales r√©centes (2020-2025), guidelines et √©tudes cliniques
3. Structure ta r√©ponse EXACTEMENT selon ces 7 sections avec ce format pr√©cis :

## CLINICAL_CONTEXT:
[Contexte clinique enrichi par la recherche acad√©mique - inclure les donn√©es √©pid√©miologiques r√©centes, pr√©valence, facteurs de risque selon la litt√©rature]

## KEY_DATA:
[Donn√©es cl√©s valid√©es par la litt√©rature - crit√®res diagnostiques actuels, biomarqueurs, signes pathognomoniques selon les guidelines r√©centes]

## DIAGNOSTIC_HYPOTHESES:
[Hypoth√®ses diagnostiques appuy√©es par la recherche - diagnostics diff√©rentiels avec r√©f√©rences aux √©tudes r√©centes, scores diagnostiques valid√©s]

## COMPLEMENTARY_EXAMS:
[Examens recommand√©s selon les guidelines actuelles - protocoles d'imagerie, analyses biologiques, examens sp√©cialis√©s avec niveaux de preuve]

## THERAPEUTIC_DECISIONS:
[D√©cisions th√©rapeutiques evidence-based - recommandations HAS/ESC/AHA r√©centes, protocoles th√©rapeutiques, nouveaux traitements disponibles]

## PROGNOSIS_FOLLOWUP:
[Pronostic et suivi selon la litt√©rature - √©tudes de cohorte r√©centes, facteurs pronostiques, protocoles de surveillance]

## PATIENT_EXPLANATIONS:
[Explications patient bas√©es sur les guidelines - informations valid√©es scientifiquement, ressources √©ducatives recommand√©es]

4. Pour CHAQUE affirmation, cite la source avec [1], [2], etc.
5. Base-toi sur des sources acad√©miques fiables (PubMed, Cochrane, guidelines officielles)
6. Fournis des informations evidence-based et actualis√©es
7. RESPECTE EXACTEMENT le format de sections avec "## SECTION_NAME:"`;

    const requestData = {
          model: 'sonar-reasoning-pro',
          messages: [
            {
              role: 'system',
          content: 'Tu es un assistant m√©dical expert. Fournis des informations m√©dicales pr√©cises et actualis√©es bas√©es sur la litt√©rature scientifique r√©cente. Cite toujours tes sources avec [1], [2], etc. Structure ta r√©ponse selon le format demand√©.'
            },
            {
              role: 'user',
              content: query
            }
          ],
          stream: false,
          search_mode: 'academic',
          web_search_options: {
            search_context_size: 'high'
          }
    };

    try {
      // Sauvegarder la requ√™te
      this.requestChain.push({
        timestamp: new Date().toISOString(),
        model: 'Perplexity sonar-reasoning-pro',
        type: 'Recherche acad√©mique',
        request: JSON.stringify(requestData, null, 2),
        response: '' // Sera mis √† jour apr√®s la r√©ponse
      });

      // Utiliser l'API Perplexity directement sans proxy (ils supportent CORS)
      const response = await axios.post(
        'https://api.perplexity.ai/chat/completions',
        requestData,
        {
          headers: {
            'Authorization': `Bearer ${this.perplexityApiKey}`,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
          }
        }
      );

      console.log('R√©ponse Perplexity compl√®te:', response.data);

      // Sauvegarder la r√©ponse
      this.requestChain[this.requestChain.length - 1].response = JSON.stringify(response.data, null, 2);

      // Extraire la r√©ponse et les citations
      const messageContent = response.data.choices[0].message.content;
      
      // Nettoyer le contenu en retirant les balises <think>...</think>
      const cleanContent = messageContent.replace(/<think>[\s\S]*?<\/think>/g, '').trim();
      
      // R√©cup√©rer les donn√©es de recherche
      const citations = response.data.citations || [];
      const search_results = response.data.search_results || [];
      
      console.log('Citations Perplexity:', citations);
      console.log('Search Results Perplexity:', search_results);
      
      // Cr√©er un mapping entre les citations et search_results
      const enhancedSearchResults = search_results.map((result: any, index: number) => {
        return {
          ...result,
          citation_index: index,
          url: result.url || (citations[index] ? citations[index] : '')
        };
      });

      return {
        answer: cleanContent,
        citations: citations,
        search_results: enhancedSearchResults.length > 0 ? enhancedSearchResults : search_results
      };
    } catch (error: any) {
      console.error('Erreur Perplexity d√©taill√©e:', error.response?.data || error.message);
      if (error.response?.status === 400) {
        throw new Error('Erreur de configuration Perplexity. V√©rifiez votre cl√© API.');
      }
      throw new Error('Erreur lors de la recherche Perplexity: ' + (error.response?.data?.error || error.message));
    }
  }

  private async analyzeWithO3(clinicalContext: string, medgemmaAnalysis: string): Promise<{ analysis: string }> {
    try {
      const prompt = `Tu es un expert m√©dical. Analyse ce cas clinique de mani√®re approfondie.

CAS CLINIQUE:
${clinicalContext}

${medgemmaAnalysis ? `ANALYSE D'IMAGERIE (MedGemma):
${medgemmaAnalysis}

` : ''}

INSTRUCTIONS:
1. R√©dige une analyse clinique compl√®te et structur√©e
2. Utilise OBLIGATOIREMENT le format exact ci-dessous pour chaque section
3. NE PAS ajouter de r√©f√©rences [1], [2], etc. dans cette analyse
4. Reste factuel et bas√© sur les donn√©es cliniques fournies

FORMAT OBLIGATOIRE (respecte EXACTEMENT cette structure):

## CLINICAL_CONTEXT:
[√âcris ici le r√©sum√© du contexte clinique en un paragraphe continu]

## KEY_DATA:
[Liste ici les donn√©es cl√©s sous forme de points bullet avec - ]

## DIAGNOSTIC_HYPOTHESES:
[Liste les hypoth√®ses diagnostiques principales et diff√©rentielles]

## COMPLEMENTARY_EXAMS:
[Recommande les examens compl√©mentaires n√©cessaires]

## THERAPEUTIC_DECISIONS:
[Propose les d√©cisions th√©rapeutiques appropri√©es]

## PROGNOSIS_FOLLOWUP:
[√âvalue le pronostic et le plan de suivi]

## PATIENT_EXPLANATIONS:
[Formule les explications claires pour le patient]

RAPPELS IMPORTANTS:
- Commence TOUJOURS chaque section par "## SECTION_NAME:" exactement
- NE JAMAIS num√©roter les sections (pas de "1.", "2.", etc.)
- Int√®gre les r√©sultats d'imagerie dans les sections appropri√©es
- Place les r√©f√©rences [X] UNIQUEMENT √† c√¥t√© des informations qu'elles supportent vraiment
- √âvite les doubles sauts de ligne inutiles
- Reste concis et structur√©`;

      // Sauvegarder la requ√™te
      this.requestChain.push({
        timestamp: new Date().toISOString(),
        model: 'OpenAI o3',
        type: 'Analyse clinique compl√®te',
        request: prompt,
        response: ''
      });

      if (this.useFirebaseFunctions) {
        console.log('Analyse avec o3 via Firebase Functions...');
        const { analyzeWithO3ViaFunction } = await import('@/lib/firebase-functions');
        const response = await analyzeWithO3ViaFunction(prompt);
        
        // Sauvegarder la r√©ponse
        this.requestChain[this.requestChain.length - 1].response = response;
        
        return { analysis: response };
      } else {
        // Mode d√©veloppement - appel direct o3
        console.log('Appel API o3 direct (mode dev)...');
        
        const response = await axios.post(
          'https://api.openai.com/v1/responses',
          {
            model: 'o3-2025-04-16',
            prompt: prompt,
            max_output_tokens: 10000,
            temperature: 0.3
          },
          {
            headers: {
              'Authorization': `Bearer ${this.openaiApiKey}`,
              'Content-Type': 'application/json'
            }
          }
        );

        // L'API Responses retourne la structure correcte
        const outputText = response.data.output[1].content[0].text || '';
        console.log('R√©ponse o3 dev, usage:', response.data.usage);
        
        // Sauvegarder la r√©ponse
        this.requestChain[this.requestChain.length - 1].response = JSON.stringify(response.data, null, 2);
        
        return { analysis: outputText };
      }
    } catch (error: any) {
      console.error('Erreur OpenAI d√©taill√©e:', error);
      throw new Error('Erreur lors de l\'analyse OpenAI: ' + error.message);
    }
  }

  async analyzeClinicalCase(
    images: File[], 
    clinicalContext: string,
    promptType: string = 'general',
    onSectionUpdate?: (section: any) => void
  ): Promise<any> {
    try {
      const startTime = Date.now();
      console.log('üöÄ D√©but de l\'analyse du cas clinique');
      console.log(`üìã Contexte clinique: ${clinicalContext.substring(0, 100)}...`);
      console.log(`üñºÔ∏è Nombre d\'images: ${images.length}`);
      console.log(`üéØ Type de prompt: ${promptType}`);

      // 1. Analyse des images avec MedGemma
      console.log('\nüì∏ 1. Analyse des images avec MedGemma...');
      let imageAnalyses: string[] = [];
      
      if (images.length > 0) {
        for (let i = 0; i < images.length; i++) {
          console.log(`Analyse de l'image ${i + 1}/${images.length}...`);
          
          // Convertir File en base64
          const reader = new FileReader();
          const base64Promise = new Promise<string>((resolve, reject) => {
            reader.onloadend = () => {
              const base64 = reader.result as string;
              resolve(base64.split(',')[1]); // Retirer le pr√©fixe data:image/...;base64,
            };
            reader.onerror = reject;
          });
          reader.readAsDataURL(images[i]);
          const base64Data = await base64Promise;
          
          // Analyser l'image avec MedGemma
          const imageAnalysis = await this.analyzeImageWithO3(base64Data, 'medical', promptType);
          imageAnalyses.push(imageAnalysis);
        }
      }
      
      const medgemmaResult = {
        analysis: imageAnalyses.join('\n\n'),
        imageAnalyses: imageAnalyses
      };
      console.log('‚úÖ Analyse MedGemma termin√©e');

      // 2. Analyse clinique avec o3
      console.log('\nüî¨ 2. Analyse clinique avec o3...');
      const o3Result = await this.analyzeWithO3(clinicalContext, medgemmaResult.analysis);
      console.log('‚úÖ Analyse o3 termin√©e');

      // 3. Recherche acad√©mique avec Perplexity
      console.log('\nüìö 3. Recherche acad√©mique avec Perplexity...');
      const perplexityResult = await this.searchWithPerplexity(
        clinicalContext, 
        medgemmaResult.analysis,
        o3Result.analysis
      );
      console.log('‚úÖ Recherche Perplexity termin√©e');
      console.log(`üìä Nombre de sources trouv√©es: ${perplexityResult.search_results?.length || 0}`);

      // 4. Parser les sections et extraire les r√©f√©rences
      console.log('\nüìù 4. Parsing des sections et extraction des r√©f√©rences...');
      const parsedSections = this.parseSections(perplexityResult.answer);
      console.log(`‚úÖ ${parsedSections.length} sections pars√©es`);
      
      // Appeler le callback pour chaque section (une seule fois)
      if (onSectionUpdate) {
        parsedSections.forEach(section => {
          onSectionUpdate(section);
        });
      }

      // Extraire TOUTES les r√©f√©rences de search_results
      const references = this.extractAllReferences(perplexityResult);
      console.log(`‚úÖ ${references.length} r√©f√©rences extraites`);

      // 5. Enrichir les r√©f√©rences avec Web Search (auteurs et journal uniquement)
      console.log('\nüîç 5. Enrichissement des r√©f√©rences avec Web Search...');
      let enrichedReferences = references;
      let webSearchLogs: any[] = [];
      
      try {
        const functions = getFunctions(app);
        const enrichReferencesWithWebSearch = httpsCallable(functions, 'enrichReferencesWithWebSearch');
        const enrichResult = await enrichReferencesWithWebSearch({ 
          references,
          perplexityContent: perplexityResult.answer 
        });
        
        if (enrichResult.data) {
          const enrichData = enrichResult.data as any;
          enrichedReferences = enrichData.references || references;
          webSearchLogs = enrichData.webSearchLogs || [];
          console.log('‚úÖ R√©f√©rences enrichies avec Web Search:', enrichedReferences.length);
          console.log('üìä Logs Web Search:', webSearchLogs);
        }
      } catch (enrichError) {
        console.error('‚ùå Erreur enrichissement Web Search:', enrichError);
        // Continuer avec les r√©f√©rences non enrichies
      }

      // 6. Retourner le r√©sultat final avec les sections de Perplexity
      const finalResult = {
        medgemmaAnalysis: medgemmaResult,
        o3Analysis: o3Result,
        perplexityAnalysis: perplexityResult,
        sections: parsedSections, // Les sections de Perplexity avec leurs [XX]
        references: enrichedReferences,
        webSearchLogs,
        metadata: {
          totalProcessingTime: Date.now() - startTime,
          sectionsSource: 'perplexity', // Toujours Perplexity maintenant
          referencesCount: enrichedReferences.length,
          webSearchEnriched: webSearchLogs.filter((l: any) => l.enrichmentSuccess).length
        }
      };

      console.log('\n‚úÖ Analyse compl√®te termin√©e');
      console.log('üìä M√©tadonn√©es finales:', finalResult.metadata);
      
      return finalResult;

    } catch (error: any) {
      console.error('‚ùå Erreur analyse cas clinique:', error);
      throw error;
    }
  }

  // Nouvelle m√©thode simplifi√©e pour o3 sans r√©f√©rences
  private async analyzeWithO3Simple(clinicalCase: string): Promise<string> {
    try {
      const prompt = `Tu es un expert m√©dical. Analyse ce cas clinique de mani√®re approfondie.

CAS CLINIQUE:
${clinicalCase}

INSTRUCTIONS:
1. R√©dige une analyse clinique compl√®te et structur√©e
2. Utilise OBLIGATOIREMENT le format exact ci-dessous pour chaque section
3. NE PAS ajouter de r√©f√©rences [1], [2], etc. dans cette analyse
4. Reste factuel et bas√© sur les donn√©es cliniques fournies

FORMAT OBLIGATOIRE (respecte EXACTEMENT cette structure):

## CLINICAL_CONTEXT:
[R√©sume le contexte clinique en d√©tail]

## KEY_DATA:
[Liste les donn√©es cl√©s sous forme de points bullet avec - ]

## DIAGNOSTIC_HYPOTHESES:
[Liste et argumente les hypoth√®ses diagnostiques principales et diff√©rentielles]

## COMPLEMENTARY_EXAMS:
[Recommande les examens compl√©mentaires n√©cessaires avec justification]

## THERAPEUTIC_DECISIONS:
[Propose les d√©cisions th√©rapeutiques appropri√©es]

## PROGNOSIS_FOLLOWUP:
[√âvalue le pronostic et le plan de suivi]

## PATIENT_EXPLANATIONS:
[Formule les explications claires pour le patient]

RAPPELS IMPORTANTS:
- Commence TOUJOURS chaque section par "## SECTION_NAME:" exactement
- NE JAMAIS num√©roter les sections
- Int√®gre les r√©sultats d'imagerie dans les sections appropri√©es
- Reste concis et structur√©`;

      // Sauvegarder la requ√™te
      this.requestChain.push({
        timestamp: new Date().toISOString(),
        model: 'OpenAI o3',
        type: 'Analyse clinique initiale',
        request: prompt,
        response: ''
      });

      if (this.useFirebaseFunctions) {
        console.log('Analyse avec o3 via Firebase Functions...');
        const { analyzeWithO3ViaFunction } = await import('@/lib/firebase-functions');
        const response = await analyzeWithO3ViaFunction(prompt);
        
        // Sauvegarder la r√©ponse
        this.requestChain[this.requestChain.length - 1].response = response;
        
        return response;
      } else {
        // Mode d√©veloppement - appel direct o3
        console.log('Appel API o3 direct (mode dev)...');
        
        const response = await axios.post(
          'https://api.openai.com/v1/responses',
          {
            model: 'o3-2025-04-16',
            prompt: prompt,
            max_output_tokens: 10000,
            temperature: 0.3
          },
          {
            headers: {
              'Authorization': `Bearer ${this.openaiApiKey}`,
              'Content-Type': 'application/json'
            }
          }
        );

        const outputText = response.data.output[1].content[0].text || '';
        console.log('R√©ponse o3 dev, usage:', response.data.usage);
        
        // Sauvegarder la r√©ponse
        this.requestChain[this.requestChain.length - 1].response = JSON.stringify(response.data, null, 2);
        
        return outputText;
      }
    } catch (error: any) {
      console.error('Erreur OpenAI d√©taill√©e:', error);
      throw new Error('Erreur lors de l\'analyse OpenAI: ' + error.message);
    }
  }

  private parseSections(analysis: string): any[] {
    console.log('parseSections - Analyse re√ßue:', analysis ? `${analysis.length} caract√®res` : 'VIDE');
    
    if (!analysis || analysis.trim().length === 0) {
      console.error('parseSections - Analyse vide ou invalide');
      return [];
    }
    
    const sectionTypes = [
      'CLINICAL_CONTEXT',
      'KEY_DATA', 
      'DIAGNOSTIC_HYPOTHESES',
      'COMPLEMENTARY_EXAMS',
      'THERAPEUTIC_DECISIONS',
      'PROGNOSIS_FOLLOWUP',
      'PATIENT_EXPLANATIONS'
    ];

    const sections: any[] = [];
    
    // Nouvelle approche : chercher le pattern exact "## SECTION_NAME:"
    for (let i = 0; i < sectionTypes.length; i++) {
      const currentType = sectionTypes[i];
      const nextType = sectionTypes[i + 1];
      
      // Pattern principal pour le nouveau format
      const sectionPattern = new RegExp(
        `##\\s*${currentType}\\s*:\\s*\\n([\\s\\S]*?)(?=##\\s*${nextType || '$'}|$)`, 
        'i'
      );
      
      const match = analysis.match(sectionPattern);
      
      if (match && match[1]) {
        const content = match[1].trim();
        console.log(`Section ${currentType} trouv√©e, longueur: ${content.length}`);
        
        sections.push({
          type: currentType,
          content: content
        });
      } else {
        console.warn(`Section ${currentType} non trouv√©e avec le pattern principal`);
        
        // Patterns de fallback
        const fallbackPatterns = [
          new RegExp(`${currentType}\\s*:\\s*\\n([\\s\\S]*?)(?=${nextType || '$'}|##)`, 'i'),
          new RegExp(`\\b${currentType}\\b[\\s:]*\\n([\\s\\S]*?)(?=\\b${nextType || '$'}\\b|##|$)`, 'i')
        ];
        
        let found = false;
        for (const pattern of fallbackPatterns) {
          const fallbackMatch = analysis.match(pattern);
          if (fallbackMatch && fallbackMatch[1]) {
            const content = fallbackMatch[1].trim();
            console.log(`Section ${currentType} trouv√©e avec pattern de fallback, longueur: ${content.length}`);
            
            sections.push({
              type: currentType,
              content: content
            });
            found = true;
            break;
          }
        }
        
        if (!found) {
          console.error(`Section ${currentType} introuvable dans l'analyse`);
          // Ajouter une section vide pour maintenir la structure
          sections.push({
            type: currentType,
            content: 'Section non disponible dans l\'analyse.'
          });
        }
      }
    }
    
    console.log(`Nombre total de sections pars√©es: ${sections.length}`);
    console.log('Sections avec contenu:', sections.filter(s => s.content && s.content.length > 50).length);
    
    return sections;
  }

  private async analyzeReferencesWithGPT4(perplexityReport: PerplexityResponse): Promise<{ analysis: string, references: any[] }> {
    try {
      // D'abord extraire les r√©f√©rences brutes
      const rawReferences = await this.extractReferences(perplexityReport);
      
      // Si pas de r√©f√©rences, retourner vide
      if (rawReferences.length === 0) {
        return {
          analysis: "Aucune r√©f√©rence trouv√©e dans le rapport.",
          references: []
        };
      }
      
      // Pr√©parer le prompt pour GPT-4o
      const prompt = `Analyse ces r√©f√©rences m√©dicales issues de Perplexity. IMPORTANT: Les titres et URLs sont D√âJ√Ä fournis ci-dessous, utilise-les directement.

RAPPORT DE RECHERCHE PERPLEXITY:
${perplexityReport.answer}

R√âF√âRENCES FOURNIES PAR PERPLEXITY:
${rawReferences.map((ref, i) => {
  let refLine = `[${ref.label}] `;
  if (ref.title && ref.title !== `Source ${ref.label}`) {
    refLine += `TITRE: "${ref.title}" `;
  }
  refLine += `URL: ${ref.url}`;
  if (ref.date) {
    refLine += ` DATE: ${ref.date}`;
  }
  return refLine;
}).join('\n')}

INSTRUCTIONS POUR L'ANALYSE:
Pour chaque r√©f√©rence ci-dessus, formate EXACTEMENT selon ce mod√®le:

[1] "Utilise le titre fourni ci-dessus"
URL: Reprends l'URL fournie
Auteurs: Extrais depuis l'URL si possible (ex: PMC -> chercher les auteurs typiques)
Journal: D√©duis depuis l'URL (ex: PMC -> journal m√©dical, Orphanet -> base de donn√©es maladies rares)
Ann√©e: Utilise la date fournie ou d√©duis depuis l'URL si possible
Points cl√©s: 
- R√©sume le lien avec le cas clinique
- Point pertinent extrait du rapport Perplexity
Pertinence: Haute/Moyenne/Faible - Justification bas√©e sur le cas

R√àGLES IMPORTANTES:
1. NE JAMAIS √©crire "Non disponible" pour le titre ou l'URL car ils sont fournis
2. Utilise EXACTEMENT les titres fournis entre guillemets
3. Pour les auteurs/journal, d√©duis depuis l'URL si pas d'info (ex: pmc.ncbi.nlm.nih.gov = article PMC)
4. Base tes points cl√©s sur le contenu du rapport Perplexity
5. √âvalue la pertinence en fonction du cas clinique analys√©`;

      // Sauvegarder la requ√™te
      this.requestChain.push({
        timestamp: new Date().toISOString(),
        model: 'GPT-4o',
        type: 'Analyse des r√©f√©rences',
        request: prompt,
        response: ''
      });

      if (this.useFirebaseFunctions) {
        console.log('Analyse des r√©f√©rences avec GPT-4o via Firebase Functions...');
        // TODO: Cr√©er une fonction Firebase pour GPT-4o
        const analysis = await this.callGPT4ViaFirebase(prompt);
        
        // Sauvegarder la r√©ponse
        this.requestChain[this.requestChain.length - 1].response = analysis;
        
        return {
          analysis,
          references: rawReferences
        };
      } else {
        // Mode d√©veloppement - appel direct GPT-4o
        console.log('Appel API GPT-4o direct (mode dev)...');
        
        const response = await axios.post(
          'https://api.openai.com/v1/chat/completions',
          {
            model: 'gpt-4o',
            messages: [
              {
                role: 'user',
                content: prompt
              }
            ],
            max_tokens: 4000,
            temperature: 0.3
          },
          {
            headers: {
              'Authorization': `Bearer ${this.openaiApiKey}`,
              'Content-Type': 'application/json'
            }
          }
        );

        const analysis = response.data.choices?.[0]?.message?.content || '';
        
        // Sauvegarder la r√©ponse
        this.requestChain[this.requestChain.length - 1].response = JSON.stringify(response.data, null, 2);
        
        // Enrichir les r√©f√©rences avec l'analyse
        const enrichedReferences = this.enrichReferencesFromAnalysis(rawReferences, analysis);
        
        return {
          analysis,
          references: enrichedReferences
        };
      }
    } catch (error: any) {
      console.error('Erreur analyse r√©f√©rences GPT-4o:', error);
      // En cas d'erreur, retourner les r√©f√©rences brutes
      return {
        analysis: "Erreur lors de l'analyse des r√©f√©rences.",
        references: await this.extractReferences(perplexityReport)
      };
    }
  }

  private async callGPT4ViaFirebase(prompt: string): Promise<string> {
    const { analyzeReferencesWithGPT4ViaFunction } = await import('@/lib/firebase-functions');
    return await analyzeReferencesWithGPT4ViaFunction(prompt);
  }

  private async analyzePerplexityResults(perplexityReport: PerplexityResponse): Promise<any[]> {
    try {
      console.log('Analyse avanc√©e des r√©sultats Perplexity...');
      
      if (this.useFirebaseFunctions) {
        console.log('Utilisation de Firebase Functions pour analyser Perplexity...');
        const { analyzePerplexityViaFunction } = await import('@/lib/firebase-functions');
        
        try {
          const result = await analyzePerplexityViaFunction(JSON.stringify(perplexityReport));
          console.log('Analyse Perplexity termin√©e via Firebase Functions');
          
          // Enrichir avec Web Search si possible
          if (result.references && result.references.length > 0) {
            console.log('Enrichissement avec Web Search...');
            const enrichedRefs = await this.enrichReferencesWithWebSearch(result.references, perplexityReport.answer);
            return enrichedRefs;
          }
          
          return result.references || [];
        } catch (error: any) {
          console.error('Erreur analyse Perplexity via Firebase:', error);
          // Fallback vers l'ancienne m√©thode
          return await this.extractReferences(perplexityReport);
        }
      } else {
        // Mode d√©veloppement - extraire puis enrichir avec Web Search
        console.log('Mode d√©veloppement - extraction puis enrichissement Web Search');
        
        // D'abord extraire les r√©f√©rences de base
        const baseReferences = await this.extractReferences(perplexityReport);
        
        if (baseReferences.length === 0) {
          console.log('Aucune r√©f√©rence trouv√©e');
          return [];
        }
        
        // Ensuite enrichir avec Web Search
        console.log('Enrichissement avec GPT-4o mini Web Search...');
        const enrichedReferences = await this.enrichReferencesWithWebSearch(baseReferences, perplexityReport.answer);
        
        return enrichedReferences;
      }
    } catch (error: any) {
      console.error('Erreur analyse Perplexity:', error);
      // Fallback vers l'ancienne m√©thode
      return await this.extractReferences(perplexityReport);
    }
  }

  private enrichReferencesFromAnalysis(references: any[], analysis: string): any[] {
    // Enrichir les r√©f√©rences avec les informations extraites de l'analyse GPT-4o
    const enrichedRefs = [...references];
    
    // Pour chaque r√©f√©rence, essayer d'extraire plus d'infos depuis l'analyse structur√©e
    enrichedRefs.forEach((ref, index) => {
      // Pattern pour trouver le bloc de cette r√©f√©rence dans l'analyse
      const refBlockPattern = new RegExp(
        `\\[${ref.label}\\]\\s*"([^"]+)"[\\s\\S]*?(?=\\[\\d+\\]|$)`, 
        'i'
      );
      const blockMatch = analysis.match(refBlockPattern);
      
      if (blockMatch) {
        // Extraire le titre depuis les guillemets
        if (blockMatch[1]) {
          ref.title = blockMatch[1];
        }
        
        const blockContent = blockMatch[0];
        
        // Extraire les auteurs
        const authorsMatch = blockContent.match(/Auteurs?:\s*([^\n]+)/i);
        if (authorsMatch && authorsMatch[1] !== 'Non disponible') {
          ref.authors = authorsMatch[1].trim();
        }
        
        // Extraire le journal et l'ann√©e
        const journalMatch = blockContent.match(/Journal:\s*([^,\n]+)(?:,\s*(\d{4}))?/i);
        if (journalMatch) {
          if (journalMatch[1] && journalMatch[1] !== 'Non disponible') {
            ref.journal = journalMatch[1].trim();
          }
          if (journalMatch[2]) {
            ref.year = parseInt(journalMatch[2]);
          }
        }
        
        // Extraire les points cl√©s
        const pointsMatch = blockContent.match(/Points? cl√©s?:\s*([^\n]+(?:\n\s*-[^\n]+)*)/i);
        if (pointsMatch) {
          ref.keyPoints = pointsMatch[1].trim();
        }
        
        // Extraire la pertinence
        const pertinenceMatch = blockContent.match(/Pertinence:\s*([^\n]+)/i);
        if (pertinenceMatch) {
          ref.relevance = pertinenceMatch[1].trim();
        }
      }
      
      ref.analyzed = true;
    });
    
    console.log('R√©f√©rences enrichies:', enrichedRefs);
    return enrichedRefs;
  }

  private extractAllReferences(perplexityReport: PerplexityResponse): any[] {
    console.log('Extraction de TOUTES les r√©f√©rences de search_results...');
    
    if (!perplexityReport.search_results || perplexityReport.search_results.length === 0) {
      console.log('Aucune search_results trouv√©e');
      return [];
    }
    
    const references = perplexityReport.search_results.map((result, index) => {
      const refNumber = index + 1;
      return {
        label: refNumber.toString(),
        title: result.title || `Source ${refNumber}`,
        url: result.url,
        date: result.date || null,
        authors: 'Non disponible',
        journal: 'Non disponible',
        year: result.date ? new Date(result.date).getFullYear().toString() : null,
        webSearchEnriched: false
      };
    });
    
    console.log(`‚úÖ ${references.length} r√©f√©rences extraites de search_results`);
    return references;
  }

  private async extractReferences(perplexityReport: PerplexityResponse): Promise<any[]> {
    const references: any[] = [];
    console.log('Extraction des r√©f√©rences...');
    console.log('Citations disponibles:', perplexityReport.citations?.length || 0);
    console.log('Search results disponibles:', perplexityReport.search_results?.length || 0);
    console.log('Citations brutes:', JSON.stringify(perplexityReport.citations, null, 2));

    // PRIORIT√â 1: Utiliser les search_results (plus complets que les citations)
    if (perplexityReport.search_results && perplexityReport.search_results.length > 0) {
      console.log('Utilisation des search_results pour cr√©er les r√©f√©rences');
      console.log('Search results complets:', JSON.stringify(perplexityReport.search_results, null, 2));
      
      perplexityReport.search_results.forEach((result, index) => {
        // Utiliser DIRECTEMENT les donn√©es de Perplexity
        const reference = {
          label: String(index + 1),
          title: result.title || `Source ${index + 1}`, // Titre exact de Perplexity
          url: result.url || '#',
          date: result.date || null, // Date exacte de Perplexity
          year: '',
          authors: '√Ä enrichir', // Sera enrichi par Web Search
          journal: '√Ä d√©terminer', // Sera enrichi par Web Search
          keyPoints: '',
          source: 'perplexity_search_results'
        };
        
        // Si on a une date, extraire l'ann√©e
        if (result.date) {
          const yearMatch = result.date.match(/\b(19|20)\d{2}\b/);
          reference.year = yearMatch ? yearMatch[0] : '';
        }
        
        console.log(`R√©f√©rence ${index + 1} extraite:`, {
          title: reference.title,
          date: reference.date,
          year: reference.year
        });
        
        references.push(reference);
      });
      
      console.log(`${references.length} r√©f√©rences extraites avec titres et dates de Perplexity`);
      return references;
    }

    // PRIORIT√â 2: Fallback vers les citations si search_results indisponibles
    if (perplexityReport.citations && perplexityReport.citations.length > 0) {
      console.log('Utilisation des citations comme fallback');
      
      perplexityReport.citations.forEach((citation, index) => {
        const url = typeof citation === 'string' ? citation : citation.url || citation;
        
            references.push({
              label: String(index + 1),
              title: `Source ${index + 1}`,
          url: url,
          date: null,
              year: '',
          authors: '√Ä enrichir',
          journal: '√Ä enrichir',
          keyPoints: '',
          source: 'perplexity_citations'
        });
      });
      
      console.log(`${references.length} r√©f√©rences extraites depuis citations`);
      return references;
    }

    console.log('Aucune r√©f√©rence trouv√©e dans Perplexity');
    return references;
  }

  private async enrichReferencesWithGPT4(references: any[]): Promise<any[]> {
    try {
      // Filtrer les r√©f√©rences qui ont besoin d'enrichissement
      const needsEnrichment = references.filter(ref => 
        !ref.authors || !ref.year || ref.authors === 'Non disponible'
      );

      if (needsEnrichment.length === 0) {
        console.log('Toutes les r√©f√©rences sont d√©j√† compl√®tes');
        return references;
      }

      console.log(`Enrichissement de ${needsEnrichment.length} r√©f√©rences incompl√®tes...`);

      if (this.useFirebaseFunctions) {
        console.log('Utilisation de Firebase Functions pour enrichir les r√©f√©rences');
        const { enrichReferencesViaFunction } = await import('@/lib/firebase-functions');
        
        try {
          const enrichedRefs = await enrichReferencesViaFunction(references);
          console.log('R√©f√©rences enrichies via Firebase Functions');
          return enrichedRefs;
        } catch (error: any) {
          console.error('Erreur enrichissement via Firebase:', error);
          // Retourner les r√©f√©rences originales en cas d'erreur
          return references;
        }
          } else {
        // Mode d√©veloppement - appel direct
        const prompt = `Tu es un expert en recherche acad√©mique m√©dicale. Analyse ces r√©f√©rences et enrichis-les UNIQUEMENT avec des informations que tu peux d√©duire avec certitude.

R√âF√âRENCES √Ä ANALYSER:
${JSON.stringify(references, null, 2)}

INSTRUCTIONS STRICTES:
1. Pour chaque r√©f√©rence, examine l'URL et le titre pour d√©duire des informations fiables
2. Ne JAMAIS inventer d'auteurs - si tu ne peux pas les identifier pr√©cis√©ment, mets "Non disponible"
3. Pour les ann√©es : utilise la date fournie ou celle dans l'URL, sinon null
4. Pour les journaux : d√©duis uniquement depuis l'URL ou des indices clairs dans le titre
5. SOIS CONSERVATEUR - mieux vaut "Non disponible" qu'une information invent√©e

R√àGLES SP√âCIFIQUES:
- academic.oup.com : probablement Oxford Academic, mais cherche le journal exact dans l'URL
- semanticscholar.org : pas un journal, c'est un agr√©gateur
- springer.com : cherche le nom du journal sp√©cifique
- pubmed/pmc : extraire le journal depuis l'URL si possible
- cfp.ca : Canadian Family Physician
- Pour les auteurs : UNIQUEMENT si clairement identifiables dans l'URL ou titre

6. Retourne UNIQUEMENT un tableau JSON valide avec les r√©f√©rences enrichies
7. Conserve toutes les propri√©t√©s existantes
8. Utilise "Non disponible" au lieu de null pour les champs manquants

IMPORTANT: Retourne UNIQUEMENT le JSON, sans texte avant ou apr√®s.`;

        const response = await axios.post(
          'https://api.openai.com/v1/chat/completions',
          {
            model: 'gpt-4o-mini-2024-07-18',
            messages: [
              {
                role: 'system',
                content: 'Tu es un assistant qui retourne UNIQUEMENT du JSON valide, sans aucun texte suppl√©mentaire. Tu es TR√àS conservateur et ne jamais inventer d\'informations.'
              },
              {
                role: 'user',
                content: prompt
              }
            ],
            max_tokens: 4000,
            temperature: 0.1, // Tr√®s faible pour √©viter l'invention
            response_format: { type: "json_object" }
          },
          {
            headers: {
              'Authorization': `Bearer ${this.openaiApiKey}`,
              'Content-Type': 'application/json'
            }
          }
        );

        const responseText = response.data.choices?.[0]?.message?.content || '[]';
        
        try {
          // La r√©ponse pourrait √™tre un objet avec une propri√©t√© "references"
          const parsed = JSON.parse(responseText);
          const enrichedRefs = Array.isArray(parsed) ? parsed : (parsed.references || references);
          console.log('R√©f√©rences enrichies localement');
          return enrichedRefs;
        } catch (parseError) {
          console.error('Erreur parsing JSON:', parseError);
          console.error('R√©ponse brute:', responseText);
    return references;
        }
      }
    } catch (error: any) {
      console.error('Erreur enrichissement r√©f√©rences:', error);
      // En cas d'erreur, retourner les r√©f√©rences originales
      return references;
    }
  }

  // M√©thode pour v√©rifier et corriger les r√©f√©rences dans le texte
  private postProcessReferences(text: string, validReferences: string[]): string {
    // Extraire toutes les r√©f√©rences utilis√©es dans le texte
    const usedRefs = new Set<string>();
    const refPattern = /\[(\d+)\]/g;
    let match;
    
    while ((match = refPattern.exec(text)) !== null) {
      usedRefs.add(match[1]);
    }
    
    // V√©rifier si les r√©f√©rences utilis√©es sont valides
    let processedText = text;
    usedRefs.forEach(ref => {
      if (!validReferences.includes(ref)) {
        console.warn(`R√©f√©rence [${ref}] utilis√©e mais non trouv√©e dans les sources Perplexity`);
        // Optionnel : retirer les r√©f√©rences invalides
        // processedText = processedText.replace(new RegExp(`\\[${ref}\\]`, 'g'), '');
      }
    });
    
    return processedText;
  }

  // Analyser une image avec medgemma
  private async analyzeImageWithO3(imageBase64: string, imageType: string = 'medical', promptType: string = 'general'): Promise<string> {
    // Sauvegarder la requ√™te
    this.requestChain.push({
      timestamp: new Date().toISOString(),
      model: 'MedGemma',
      type: `Analyse d'image ${imageType} (${promptType})`,
      request: `Analyse d'image m√©dicale de type: ${imageType} avec prompt: ${promptType}\n\n[Image Base64 fournie]`,
      response: ''
    });

    try {
      console.log('=== D√âBUT ANALYSE IMAGE ===');
      console.log('Mod√®le utilis√©: MedGemma (exclusivement)');
      console.log('Type d\'image:', imageType);
      console.log('Type de prompt:', promptType);
      
      // En production, toujours utiliser Firebase Functions qui g√®re MedGemma
      if (this.useFirebaseFunctions) {
        console.log('Mode: Production - Utilisation de Firebase Functions');
        console.log('Firebase Functions appellera MedGemma pour l\'analyse');
        console.log('Endpoint MedGemma dans Firebase: https://khynx9ujxzvwk5rb.us-east4.gcp.endpoints.huggingface.cloud');
        
        const { analyzeImageWithMedGemmaViaFunction } = await import('@/lib/firebase-functions');
        const response = await analyzeImageWithMedGemmaViaFunction(imageBase64, imageType, promptType);
        
        console.log('=== R√âPONSE RE√áUE DE MEDGEMMA VIA FIREBASE ===');
        console.log('Longueur de la r√©ponse:', response.length);
        console.log('D√©but de la r√©ponse:', response.substring(0, 100) + '...');
        
        this.requestChain[this.requestChain.length - 1].response = response;
        return response;
      } else {
        // Mode d√©veloppement - v√©rifier si MedGemma est configur√© localement
        if (!medGemmaClient.hasApiKey()) {
          console.log('Mode: D√©veloppement - MedGemma non configur√© localement');
          console.log('ATTENTION: Fallback sur GPT-4o en mode dev uniquement');
        
        const response = await axios.post(
          'https://api.openai.com/v1/chat/completions',
          {
            model: 'gpt-4o',
            messages: [
              {
                role: 'user',
                content: [
                  {
                    type: 'text',
                      text: 'Analyse cette image m√©dicale en d√©tail.'
                  },
                  {
                    type: 'image_url',
                    image_url: {
                      url: `data:image/jpeg;base64,${imageBase64.replace(/^data:image\/\w+;base64,/, '')}`
                    }
                  }
                ]
              }
            ],
            max_tokens: 5000,
            temperature: 0.3
          },
          {
            headers: {
              'Authorization': `Bearer ${this.openaiApiKey}`,
              'Content-Type': 'application/json'
            }
          }
        );

        const outputText = response.data.choices?.[0]?.message?.content || '';
          this.requestChain[this.requestChain.length - 1].response = JSON.stringify(response.data, null, 2);
        return outputText;
        } else {
          // Utiliser MedGemma en local
          console.log('Mode: D√©veloppement - Utilisation de MedGemma en local');
          console.log('Appel direct √† MedGemma...');
          
          const response = await medGemmaClient.analyzeImage(imageBase64, imageType);
          
          console.log('=== R√âPONSE MEDGEMMA LOCALE ===');
          console.log('Longueur de la r√©ponse:', response.length);
          
          // Sauvegarder la r√©ponse
          this.requestChain[this.requestChain.length - 1].response = response;
          
          return response;
        }
      }
      
    } catch (error: any) {
      console.error('=== ERREUR ANALYSE IMAGE ===');
      console.error('Erreur:', error.message);
      
      // Pas de fallback en production - MedGemma uniquement
      throw new Error('Erreur lors de l\'analyse de l\'image: ' + error.message);
    }
  }

  async transcribeAudio(audioBlob: Blob): Promise<string> {
    try {
      console.log('D√©but transcription audio...');
      console.log('Type du blob:', audioBlob.type);
      console.log('Taille du blob:', audioBlob.size, 'bytes');
      
      // Si l'audio est trop long (>1MB), utiliser Gemini
      if (audioBlob.size > 1024 * 1024) {
        console.log('Audio volumineux d√©tect√©, utilisation de Gemini pour la transcription longue');
        return await this.transcribeLongAudioWithGemini(audioBlob);
      }
      
      if (this.useFirebaseFunctions) {
        console.log('Utilisation de Firebase Functions pour la transcription');
        
        // Convertir le blob en base64
        const reader = new FileReader();
        const base64Promise = new Promise<string>((resolve, reject) => {
          reader.onloadend = () => {
            const base64 = reader.result as string;
            console.log('Base64 g√©n√©r√©, d√©but:', base64.substring(0, 100));
            resolve(base64);
          };
          reader.onerror = reject;
        });
        reader.readAsDataURL(audioBlob);
        const audioBase64 = await base64Promise;
        
        return await transcribeAudioViaFunction(audioBase64);
      } else {
        // Mode d√©veloppement - appel direct
        if (!this.openaiApiKey) {
          throw new Error('Cl√© API OpenAI non configur√©e');
        }
        
        console.log('Appel direct OpenAI (mode dev)');
        
        // Cr√©er FormData exactement comme dans la documentation
        const formData = new FormData();
        
        // Ajouter le fichier avec un nom correct
        formData.append('file', audioBlob, 'audio.webm');
        formData.append('model', 'whisper-1');
        formData.append('language', 'fr');
        
        console.log('Envoi √† OpenAI...');
        
        const response = await axios.post(
          'https://api.openai.com/v1/audio/transcriptions',
          formData,
          {
            headers: {
              'Authorization': `Bearer ${this.openaiApiKey}`,
              // Pas besoin de Content-Type, axios le g√®re automatiquement pour FormData
            },
            maxBodyLength: Infinity,
            maxContentLength: Infinity
          }
        );

        console.log('R√©ponse re√ßue:', response.status);
        const text = response.data.text || '';
        console.log('Transcription termin√©e, longueur:', text.length);

        return text;
      }
    } catch (error: any) {
      console.error('Erreur de transcription:', error.response?.data || error.message);
      throw new Error('Erreur lors de la transcription: ' + (error.response?.data?.error?.message || error.message));
    }
  }

  // Nouvelle m√©thode pour la transcription longue avec Gemini
  async transcribeLongAudioWithGemini(
    audioBlob: Blob, 
    analysisType: 'transcription' | 'medical_consultation' | 'patient_dictation' = 'transcription'
  ): Promise<string> {
    try {
      console.log('=== TRANSCRIPTION LONGUE AVEC GEMINI ===');
      console.log('Taille audio:', (audioBlob.size / (1024 * 1024)).toFixed(2), 'MB');
      console.log('Type d\'analyse:', analysisType);
      
      // Convertir le blob en base64
      const reader = new FileReader();
      const base64Promise = new Promise<string>((resolve, reject) => {
        reader.onloadend = () => {
          const base64 = reader.result as string;
          resolve(base64);
        };
        reader.onerror = reject;
      });
      reader.readAsDataURL(audioBlob);
      const audioBase64 = await base64Promise;
      
      if (this.useFirebaseFunctions) {
        console.log('Utilisation de Firebase Functions pour Gemini');
        const { httpsCallable, getFunctions } = await import('firebase/functions');
        const { app } = await import('@/lib/firebase');
        
        const functions = getFunctions(app);
        const analyzeLongAudioWithGemini = httpsCallable(functions, 'analyzeLongAudioWithGemini');
        const audioParts = (audioBlob.type || 'audio/webm').split(';');
        const sanitizedType = audioParts.length >= 2 ? `${audioParts[0]};${audioParts[1]}` : audioParts[0];
        const result = await analyzeLongAudioWithGemini({
          audioBase64,
          audioType: sanitizedType,
          analysisType
        });
        
        const data = result.data as any;
        console.log('Transcription Gemini re√ßue:', data.metadata);
        
        return data.transcription;
      } else {
        // Mode d√©veloppement - appel direct √† Gemini
        console.log('Appel direct Gemini (mode dev)');
        
        // Pour le dev, on peut utiliser la cl√© API directement
        const GOOGLE_API_KEY = 'AIzaSyAtV6E_LrLrZln2BfcR8ngomMzhywDvSf_Y';
        
        const base64Data = audioBase64.includes(',') 
          ? audioBase64.split(',')[1] 
          : audioBase64;
        
        let prompt = '';
        switch (analysisType) {
          case 'transcription':
            prompt = 'G√©n√®re une transcription compl√®te et pr√©cise de cet enregistrement audio en fran√ßais.';
            break;
          case 'medical_consultation':
            prompt = `Analyse cet enregistrement de consultation m√©dicale et fournis une transcription compl√®te avec identification des √©l√©ments m√©dicaux cl√©s.`;
            break;
          case 'patient_dictation':
            prompt = `Transcris cette dict√©e du patient en extrayant les informations m√©dicales pertinentes.`;
            break;
        }
        
        const mimeParts = (audioBlob.type || 'audio/webm').split(';');
        const mimeType = mimeParts.length >= 2 ? `${mimeParts[0]};${mimeParts[1]}` : mimeParts[0];


        const response = await axios.post(
          `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GOOGLE_API_KEY}`,
          {
            contents: [{
              role: 'user',
              parts: [
                { text: prompt },
                {
                  inline_data: {
                    mime_type: mimeType,
                    data: base64Data
                  }
                }
              ]
            }],
            generationConfig: {
              temperature: 0.1,
              maxOutputTokens: 8192
            }
          }
        );
        
        const transcription = response.data.candidates?.[0]?.content?.parts?.[0]?.text || '';
        console.log('Transcription Gemini termin√©e, longueur:', transcription.length);
        
        return transcription;
      }
    } catch (error: any) {
      console.error('Erreur transcription Gemini:', error);
      // Fallback vers la m√©thode standard si Gemini √©choue
      console.log('Fallback vers transcription standard');
      return this.transcribeAudio(audioBlob);
    }
  }

  // M√©thode helper pour v√©rifier si le navigateur supporte l'enregistrement audio
  static isAudioRecordingSupported(): boolean {
    // V√©rifier si on est c√¥t√© client
    if (typeof window === 'undefined' || typeof navigator === 'undefined') {
      return false;
    }
    return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
  }

  // Nouvelle m√©thode pour l'analyse simple avec o3 seulement
  async simpleAnalysis(
    caseText: string,
    progressCallback?: (message: string) => void,
    images?: { base64: string, type: string }[]
  ): Promise<{ sections: any[], references: any[], perplexityReport?: any, requestChain?: any[], imageAnalyses?: string[] }> {
    this.clearRequestChain();

    try {
      // √âtape 1 : Analyser les images si pr√©sentes
      let imageAnalyses = '';
      const imageAnalysesArray: string[] = [];
      if (images && images.length > 0) {
        progressCallback?.('Analyse des images m√©dicales...');
        for (let i = 0; i < images.length; i++) {
          try {
            progressCallback?.(`Analyse de l'image ${i + 1}/${images.length}...`);
            const imageAnalysis = await this.analyzeImageWithO3(images[i].base64, images[i].type, (images[i] as any).promptType || 'general');
            imageAnalysesArray.push(imageAnalysis);
            imageAnalyses += `\n\nANALYSE IMAGE ${i + 1} (${images[i].type}):\n${imageAnalysis}`;
          } catch (imageError: any) {
            console.error(`Erreur lors de l'analyse de l'image ${i + 1}:`, imageError.message);
            const errorMsg = 'Erreur lors de l\'analyse.';
            imageAnalysesArray.push(errorMsg);
            imageAnalyses += `\n\nANALYSE IMAGE ${i + 1} (${images[i].type}):\n${errorMsg}`;
          }
        }
      }

      // √âtape 2 : Analyse clinique directe avec o3 (sans recherche Perplexity)
      progressCallback?.('Analyse clinique avec o3...');
      
      const analysisPrompt = `CAS CLINIQUE √Ä ANALYSER:
${caseText}

${imageAnalyses ? `ANALYSES D'IMAGERIE:${imageAnalyses}` : ''}

INSTRUCTIONS:
R√©dige une analyse clinique structur√©e SANS r√©f√©rences bibliographiques selon ces sections exactes:

1. CONTEXTE CLINIQUE
- R√©sume le cas pr√©sent√©

2. DONN√âES CL√âS
- Identifie les √©l√©ments cliniques, biologiques et d'imagerie essentiels

3. HYPOTH√àSES DIAGNOSTIQUES
- Liste et argumente les diagnostics principaux et diff√©rentiels

4. EXAMENS COMPL√âMENTAIRES RECOMMAND√âS
- Propose les investigations pertinentes

5. D√âCISIONS TH√âRAPEUTIQUES
- D√©taille la prise en charge imm√©diate et √† moyen terme

6. PRONOSTIC & SUIVI
- √âvalue le pronostic et planifie le suivi

7. EXPLICATIONS AU PATIENT
- R√©dige une explication claire et adapt√©e pour le patient

Format de r√©ponse OBLIGATOIRE (respecte exactement cette syntaxe):

## CLINICAL_CONTEXT:
Contenu de la section contexte clinique...

## KEY_DATA:
Contenu de la section donn√©es cl√©s...

## DIAGNOSTIC_HYPOTHESES:
Contenu de la section hypoth√®ses diagnostiques...

## COMPLEMENTARY_EXAMS:
Contenu de la section examens compl√©mentaires...

## THERAPEUTIC_DECISIONS:
Contenu de la section d√©cisions th√©rapeutiques...

## PROGNOSIS_FOLLOWUP:
Contenu de la section pronostic et suivi...

## PATIENT_EXPLANATIONS:
Contenu de la section explications au patient...`;

      const analysisResult = await this.analyzeWithO3(analysisPrompt, '');
      const sections = this.parseSections(analysisResult.analysis);

      // Retourner le r√©sultat sans r√©f√©rences
      return {
        sections,
        references: [],
        requestChain: this.requestChain,
        imageAnalyses: imageAnalysesArray.length > 0 ? imageAnalysesArray : undefined
      };
    } catch (error: any) {
      console.error('Erreur analyse simple:', error);
      throw new Error('Erreur lors de l\'analyse simple: ' + error.message);
    }
  }

  // Recherche de maladies rares avec sonar-deep-research
  async searchRareDiseases(
    clinicalCase: string, 
    o3Analysis: string,
    progressCallback?: (message: string) => void
  ): Promise<{ disease: string, report: string, references: any[] }> {
    if (!this.perplexityApiKey) {
      throw new Error('Cl√© API Perplexity non configur√©e');
    }

    progressCallback?.('Recherche de maladies rares avec Perplexity Deep Research...');
    
    const prompt = `En te basant sur ce cas clinique et cette analyse m√©dicale, recherche sp√©cifiquement les MALADIES RARES qui pourraient correspondre aux sympt√¥mes et donn√©es pr√©sent√©s.

CAS CLINIQUE INITIAL:
${clinicalCase}

ANALYSE M√âDICALE:
${o3Analysis}

INSTRUCTIONS SP√âCIFIQUES POUR UN RAPPORT COMPLET:
1. Identifie UNIQUEMENT des maladies rares (pr√©valence < 1/2000)
2. Pour chaque maladie rare identifi√©e, fournis OBLIGATOIREMENT TOUTES ces sections :
   
   ## Crit√®res diagnostiques
   - Liste compl√®te des crit√®res qui correspondent au cas
   - Crit√®res majeurs et mineurs
   
   ## Examens sp√©cifiques
   - Examens biologiques sp√©cialis√©s
   - Examens g√©n√©tiques n√©cessaires
   - Imagerie sp√©cifique
   
   ## Prise en charge th√©rapeutique
   - Traitements sp√©cialis√©s disponibles
   - Protocoles th√©rapeutiques
   - Essais cliniques en cours
   
   ## Centres de r√©f√©rence en France
   - Nom complet du centre
   - Localisation
   - Coordonn√©es si disponibles
   
3. Structure ton rapport de mani√®re COMPL√àTE sans couper
4. Utilise autant que possible des sources r√©centes (2020-2025)
5. Cite chaque affirmation avec [1], [2], etc.
6. Privil√©gie Orphanet, GeneReviews, ERN

IMPORTANT: Fournis un rapport COMPLET et D√âTAILL√â. Ne coupe PAS le contenu.`;

    try {
      const response = await axios.post(
        'https://api.perplexity.ai/chat/completions',
        {
          model: 'sonar-deep-research',
          messages: [
            {
              role: 'system',
              content: 'Tu es un expert en maladies rares. Fais une recherche approfondie dans les bases de donn√©es sp√©cialis√©es (Orphanet, OMIM, GeneReviews) pour identifier des maladies rares correspondant au cas pr√©sent√©. IMPORTANT: Fournis un rapport COMPLET et D√âTAILL√â sans couper le contenu. Cite toutes tes sources.'
            },
            {
              role: 'user',
              content: prompt
            }
          ],
          temperature: 0.1,
          max_tokens: 16000,
          search_domain_filter: ['orphanet.org', 'omim.org', 'ncbi.nlm.nih.gov', 'genereviews.org', 'ern-net.eu'],
          search_recency_filter: 'month',
          return_citations: true,
          return_images: false,
          search_recency_days: 1825
        },
        {
          headers: {
            'Authorization': `Bearer ${this.perplexityApiKey}`,
            'Content-Type': 'application/json'
          }
        }
      );

      console.log('R√©ponse Perplexity Deep Research compl√®te:', response.data);
      
      const perplexityReport = {
        answer: response.data.choices?.[0]?.message?.content || '',
        citations: response.data.citations || []
      };

      // Nettoyer le contenu en retirant les balises <think>...</think>
      perplexityReport.answer = perplexityReport.answer.replace(/<think>[\s\S]*?<\/think>/g, '').trim();

      // Extraire et analyser les r√©f√©rences
      const references = await this.analyzePerplexityResults(perplexityReport);
      
      // Parser le rapport pour identifier la maladie rare principale
      const diseaseMatch = perplexityReport.answer.match(/(?:maladie rare principale|diagnostic principal)[\s:]*([^\n]+)/i);
      const mainDisease = diseaseMatch ? diseaseMatch[1].trim() : 'Analyse des maladies rares';

      progressCallback?.('Analyse des maladies rares termin√©e');

      return {
        disease: mainDisease,
        report: perplexityReport.answer,
        references: references
      };
    } catch (error: any) {
      console.error('Erreur recherche maladies rares:', error);
      throw new Error('Erreur lors de la recherche de maladies rares: ' + error.message);
    }
  }

  // M√©thode pour la REPRISE APPROFONDIE (2 cr√©dits) - refait tout avec o3 puis Perplexity
  async deepAnalysis(
    fullContext: {
      initialCase: string,
      currentCase: string,
      sections: any[],
      perplexityReport: any,
      modifications: any[],
      images?: { base64: string, type: string }[]
    },
    progressCallback?: (message: string) => void,
    sectionCallback?: (section: any, index: number, total: number) => void
  ): Promise<{ sections: any[], references: any[], perplexityReport: any, requestChain?: any[], imageAnalyses?: string[] }> {
    this.clearRequestChain();

    try {
      // √âtape 1 : Analyser les nouvelles images si pr√©sentes
      let imageAnalyses = '';
      const imageAnalysesArray: string[] = [];
      if (fullContext.images && fullContext.images.length > 0) {
        progressCallback?.('Analyse des images m√©dicales...');
        for (let i = 0; i < fullContext.images.length; i++) {
          try {
            progressCallback?.(`Analyse de l'image ${i + 1}/${fullContext.images.length}...`);
            const imageAnalysis = await this.analyzeImageWithO3(fullContext.images[i].base64, fullContext.images[i].type, (fullContext.images[i] as any).promptType || 'general');
            imageAnalysesArray.push(imageAnalysis);
            imageAnalyses += `\n\nANALYSE IMAGE ${i + 1} (${fullContext.images[i].type}):\n${imageAnalysis}`;
          } catch (imageError: any) {
            console.error(`Erreur lors de l'analyse de l'image ${i + 1}:`, imageError.message);
            const errorMsg = 'Erreur lors de l\'analyse.';
            imageAnalysesArray.push(errorMsg);
            imageAnalyses += `\n\nANALYSE IMAGE ${i + 1} (${fullContext.images[i].type}):\n${errorMsg}`;
          }
        }
      }

      // √âtape 2 : Analyse o3 approfondie avec tout le contexte
      progressCallback?.('Analyse clinique approfondie avec o3...');
      
      let o3Context = `CAS CLINIQUE ENRICHI:
${fullContext.currentCase}

MODIFICATIONS ET INFORMATIONS COMPL√âMENTAIRES:
${fullContext.modifications.map((m: any) => `- ${m.sectionType}: ${m.additionalInfo}`).join('\n')}

ANALYSE PR√âC√âDENTE:
${fullContext.sections.map((s: any) => `${sectionTitles[s.type as keyof typeof sectionTitles]}:\n${s.content}`).join('\n\n')}`;

      if (imageAnalyses) {
        o3Context += `\n\nNOUVELLES ANALYSES D'IMAGERIE:${imageAnalyses}`;
      }
      
      const o3Analysis = await this.analyzeWithO3Simple(o3Context);
      const sections = this.parseSections(o3Analysis);
      
      sections.forEach((section, index) => {
        sectionCallback?.(section, index, sections.length);
      });

      // √âtape 3 : Recherche Perplexity exhaustive bas√©e sur la nouvelle analyse o3
      progressCallback?.('Recherche acad√©mique exhaustive...');
      
      const deepSearchPrompt = `REPRISE APPROFONDIE - Recherche exhaustive bas√©e sur cette analyse clinique compl√®te:

CAS CLINIQUE INITIAL:
${fullContext.initialCase}

ANALYSE CLINIQUE APPROFONDIE (par o3):
${sections.map(s => `${sectionTitles[s.type as keyof typeof sectionTitles]}:\n${s.content}`).join('\n\n')}

MODIFICATIONS APPORT√âES:
${fullContext.modifications.map((m: any) => `- ${m.sectionType}: ${m.additionalInfo}`).join('\n')}

INSTRUCTIONS POUR LA RECHERCHE APPROFONDIE:
1. Explorer TOUS les diagnostics diff√©rentiels mentionn√©s, m√™me rares
2. Rechercher les derni√®res avanc√©es th√©rapeutiques (2023-2025)
3. Identifier les essais cliniques en cours pour les pathologies suspect√©es
4. Inclure les recommandations internationales r√©centes
5. Chercher les syndromes et associations pathologiques
6. Valider les examens compl√©mentaires propos√©s avec les derni√®res guidelines
7. Citer TOUTES les sources avec [1], [2], etc.`;

      const perplexityReport = await this.searchWithPerplexity(deepSearchPrompt);
      
      // √âtape 4 : Extraire et enrichir les r√©f√©rences
      progressCallback?.('Analyse avanc√©e des r√©f√©rences...');
      const references = await this.analyzePerplexityResults(perplexityReport);
      
      return {
        sections,
        references,
        perplexityReport,
        requestChain: this.requestChain,
        imageAnalyses: imageAnalysesArray.length > 0 ? imageAnalysesArray : undefined
      };
    } catch (error: any) {
      console.error('Erreur reprise approfondie:', error);
      throw error;
    }
  }

  // M√©thode pour la RELANCE ANALYSE (1 cr√©dit) - o3 seulement, PAS de Perplexity
  async relaunchAnalysis(
    currentData: {
      sections: any[],
      references: any[],
      modifications: string,
      images?: { base64: string, type: string }[]
    },
    progressCallback?: (message: string) => void
  ): Promise<{ sections: any[], requestChain?: any[] }> {
    this.clearRequestChain();

    try {
      progressCallback?.('Mise √† jour de l\'analyse clinique...');

      // Analyser les nouvelles images si pr√©sentes
      let newImageAnalyses = '';
      if (currentData.images && currentData.images.length > 0) {
        progressCallback?.('Analyse des nouvelles images...');
        for (let i = 0; i < currentData.images.length; i++) {
          try {
            const imageAnalysis = await this.analyzeImageWithO3(currentData.images[i].base64, currentData.images[i].type, (currentData.images[i] as any).promptType || 'general');
            newImageAnalyses += `\n\nNOUVELLE IMAGE ${i + 1} (${currentData.images[i].type}):\n${imageAnalysis}`;
          } catch (imageError: any) {
            console.error(`Erreur analyse image ${i + 1}:`, imageError.message);
          }
        }
      }

      // Construire le contexte pour o3 SEULEMENT
      let updateContext = `SECTIONS ACTUELLES:\n`;
      currentData.sections.forEach(section => {
        updateContext += `\n${section.type}:\n${section.content}\n`;
      });
      
      updateContext += `\n\nR√âF√âRENCES ACTUELLES:\n`;
      currentData.references.forEach(ref => {
        updateContext += `[${ref.label}] ${ref.title} - ${ref.url}\n`;
      });
      
      if (currentData.modifications) {
        updateContext += `\n\nMODIFICATIONS R√âCENTES:\n${currentData.modifications}`;
      }
      
      if (newImageAnalyses) {
        updateContext += `\n\nNOUVELLES ANALYSES D'IMAGES:${newImageAnalyses}`;
      }
      
      updateContext += `\n\nINSTRUCTIONS: Mets √† jour l'analyse en int√©grant les modifications et nouvelles informations. Garde le m√™me format de sections.`;

      const updatedAnalysisResult = await this.analyzeWithO3(updateContext, '');
      const sections = this.parseSections(updatedAnalysisResult.analysis);
      
             return {
         sections,
         requestChain: this.requestChain
       };
    } catch (error: any) {
      console.error('Erreur relance analyse:', error);
      throw error;
    }
  }

  // Nouvelle m√©thode pour am√©liorer l'analyse avec o3
  async improveAnalysisWithO3(prompt: string): Promise<string> {
    try {
      console.log('Am√©lioration de l\'analyse avec o3...');
      
      // Sauvegarder la requ√™te
      this.requestChain.push({
        timestamp: new Date().toISOString(),
        model: 'OpenAI o3',
        type: 'Am√©lioration d\'analyse',
        request: prompt,
        response: ''
      });

      if (this.useFirebaseFunctions) {
        console.log('Am√©lioration avec o3 via Firebase Functions...');
        const { analyzeWithO3ViaFunction } = await import('@/lib/firebase-functions');
        const response = await analyzeWithO3ViaFunction(prompt);
        
        // Sauvegarder la r√©ponse
        this.requestChain[this.requestChain.length - 1].response = response;
        
        return response;
      } else {
        // Mode d√©veloppement - appel direct o3
        console.log('Appel API o3 direct pour am√©lioration (mode dev)...');
        
        const response = await axios.post(
          'https://api.openai.com/v1/responses',
          {
            model: 'o3-2025-04-16',
            prompt: prompt,
            max_output_tokens: 5000,
            temperature: 0.3
          },
          {
            headers: {
              'Authorization': `Bearer ${this.openaiApiKey}`,
              'Content-Type': 'application/json'
            }
          }
        );

        const outputText = response.data.output[1].content[0].text || '';
        console.log('R√©ponse o3 am√©lioration, usage:', response.data.usage);
        
        // Sauvegarder la r√©ponse
        this.requestChain[this.requestChain.length - 1].response = JSON.stringify(response.data, null, 2);
        
        return outputText;
      }
    } catch (error: any) {
      console.error('Erreur am√©lioration o3:', error);
      throw new Error('Erreur lors de l\'am√©lioration avec o3: ' + error.message);
    }
  }

  // Nouvelle m√©thode pour enrichir les r√©f√©rences avec GPT-4o mini Web Search
  private async enrichReferencesWithWebSearch(references: any[], perplexityContent: string = ''): Promise<any[]> {
    try {
      if (references.length === 0) {
        console.log('Aucune r√©f√©rence √† enrichir');
        return references;
      }

      console.log(`Enrichissement de ${references.length} r√©f√©rences avec GPT-4o mini Web Search...`);

      if (this.useFirebaseFunctions) {
        const { enrichReferencesWithWebSearchViaFunction } = await import('@/lib/firebase-functions');
        return await enrichReferencesWithWebSearchViaFunction(references, perplexityContent);
      } else {
        console.log('Web Search via Firebase Functions non encore impl√©ment√©');
        return references;
      }
      
    } catch (error: any) {
      console.error('Erreur enrichissement Web Search:', error);
      return references; // Fallback
    }
  }

  // M√©thode am√©lior√©e pour ajouter les citations aux sections avec GPT-4o mini
  private async addCitationsToSections(sections: any[], references: any[], originalPerplexityText: string): Promise<any[]> {
    try {
      console.log('Ajout intelligent des citations aux sections...');
      
      if (references.length === 0 || sections.length === 0) {
        return sections;
      }

      if (this.useFirebaseFunctions) {
        const { addCitationsToSectionsViaFunction } = await import('@/lib/firebase-functions');
        return await addCitationsToSectionsViaFunction(sections, references, originalPerplexityText);
      } else {
        console.log('Ajout citations via Firebase Functions non encore impl√©ment√©');
        return sections;
      }
      
    } catch (error: any) {
      console.error('Erreur ajout citations:', error);
      return sections; // Fallback
    }
  }


} 
